---
marp: true
theme: default
class: invert
paginate: true
title: Оптимизация большого слона — PostgteSQL
---
---
marp: true
theme: default
class: invert
paginate: true
title: Оптимизация большого слона — PostgteSQL
---

# <center>Оптимизация<br>большого слона — PostgreSQL</center>

---

### <center>простите...</center>

---

# <center>сейчас будет мясо:)</center>

---

# С чего начинается веб-приложение?

-   с одного сервера, на нём:
    -   прокси-сервер (Nginx)
    -   Application-сервер (Gunicorn)
    -   Application-код (Django / FastAPI / etc)
    -   СУБД (PostgreSQL)
    -   кэш (Redis)

---

# что из этого затупит первым?

на живом растущем проекте

---

<!--
footer: если application-код не совсем плох (что скорее всего так)
-->

# <center>СУБД!</center>

---

<!--
footer: ''
-->

# <center>что будем делать?</center>

---

# <center>утащим СУБД на отдельный сервер!</center>

---

# и это верный шаг

который поможет на какое-то время

---

# ... но потом всё снова затупит

Что делать дальше?

---

# оптимизировать запросы и настройки PostgreSQL

---

# А ещё лучше

-   стараться сразу писать оптимальные запросы
-   для этого надо уметь это делать
-   хотя крайне (крайне!) редко этому уделяют хоть какое-то внимание
-   «та у меня ORM, какие такие SQL-запросы, да ещё и какие-то эффективные?»

---

# На что это влияет?

-   быстрые SQL-запросы дают возможность быстрее отвечать на HTTP-запросы клиентов
-   быстрые HTTP-запросы — быстрые веб-страницы
-   быстрые веб-страницы — довольные клиенты
-   довольные клиенты — больше денег
-   больше денег — <strike>шире морда</strike> больше возможностей

---

# А ещё

- это больший RPS — requests per second
- больше клиентов обслуживается на одном и том же железе
- э — эффективность!

--- 

# Но главное

- что вас не будят по ночам словами «всё пропало, сайт не открывается»
- SQL-запросы имеют тенденцию сначала работать быстро и весело, а с ростом данных и нагрузки всё медленнее и грустнее, пока веб-сервисы совсем не начинают отваливаться

---

# <center>и шо же делать?</center>

---

# <center>а индекс сейчас накатим и всё взлетит!</center>

---

# <center>не фааааакт!</center>

--- 

# <center>не фааааакт!</center>

- индекс не всегда будет использоваться
- и это нормально
- а ещё индекс надо поддерживать, то есть перестраивать при изменении данных — индекс это небесплатно по вычислительным ресурсам и по месту на диске

---

# <center>БУ!</center>

---


# <center>будем разбираться глубже</center>

---

# Как PostgreSQL хранит данные?

- в файлах
- файлы разбиты на блоки по 8 килобайт, блоки называют страницами (pages)
- страница — минимальный объём, который PostgreSQL может считать с диска и записать на диск
- считать 1 строку нельзя, можно считать только одну страницу, на которой есть эта строка

---

# Буферный кеш

- после считывания страницы с диска она помещается в буферный кеш (в оперативную память) и хранится там, пока другие данные (другие считанные страницы) её не вытеснят

---

# <center>Чудненько! Как это мне поможет?</center>

--- 

# Что быстрее?

- считать 1 буфер с диска?
- считать 10 буферов с диска?
- считать 1000 буферов с диска?



---

# <center>очевидно — 1 буфер считать быстрее, чем 1000</center>

---

# <center>как использовать это тайное знание?</center>

--- 

# Например

- использовать связь один к одному вместо создания широких таблиц
- часто нужные данные, которые используются вместе, храним в одной таблице, а остальной массив данных храним отдельно в другой или других таблицах
- тогда при считывании основных данных с диска не будут читаться нужные редко данные (они лежат в другой таблице в других файлах в других страницах)

--- 

# Например

- в интернет-магазине какие данные нужны по товарам часто? Какие данные нужны на странице каталога, в корзине, в email-письме о покупке, в таблице заказов администратора?
    - артикул, название товара, цена товара, категория товара
- а характеристики товара нужны редко — только на странице конкретного одного товара (вес, размер, диагональ экрана, количество мегапикселей, длинное текстовое описание и тд)
- не клади это всё в одну таблицу, разбей на несколько!

---

# Profit!

- в основных сценариях, когда нужны данные товаров, не будут считываться данные характеристик
- быстрее будет выполняться запрос

---

# Но ведь будут же тогда JOIN!

- ну да
- и что?
- вот и я о том же
- не бойтесь JOIN, они работают очень быстро, PostgreSQL умный
- всегда надо начинать с нормализованной схемы без дублирования данных и с использованием связи 1-1 там, где это уместно:
    - разные сущности
    - разные сценарии использования

---

видео с тестами!


![bg left width:50%](images/1-1-youtube.png)

---

# `select * from table` — не для нас

- зачем тащить из СУБД то, что нам не нужно?
    - читать с файла
    - обрабатывать в СУБД
    - передавать по сети от СУБД к приложению
    - обрабатывать в приложении

---

# `select * from table` — не для нас

- сейчас в сценарии нужны все колонки?
    - а если завтра добавят в таблицу еще 20 колонок и они не нужны в том сценарии, который мы пишем, но они будут считываться, передаваться и обрабатываться из-за `select *`?

---

# `select * from table` — не для нас

- а ещё есть TOAST — текстовые данные более 8 KB не помещаются в страницу и их кладут отдельно в TOAST-таблицу, в основной таблице сохраняется ссылка на TOAST-таблицу
- и эти данные тоже будут читаться из-за `select *`, даже если они не нужны

---

# Итого — небольшой предварительный итог

1. Всегда указываем поля, которые достаём. Всегда!
2. Всега начинаем с нормализованой схемы, используем таблицы со связью один к одному вместо создания широких таблиц

---

# <center>великий и могучий и страшный `EXPLAIN`</center>

--- 

PostgreSQL даёт возможность посмотреть, как выполняется SQL-запроc. Для этого перед ним надо написать `EXPLAIN`

---

```sql
explain select * from employee;
```

---

# Что выводит `EXPLAIN`?

- план выполнения запроса
- в PostgreSQL есть оптимизатор запросов
    - он строит план выполнения запроса для наиболее эффективного его выполнения
    - он умён и коварен
    - это одна из самых ценных частей PostgreSQL
    - нам всем ОЧЕНЬ повезло, что такой оптимизатор есть в Open Source СУБД!

---

# Оптимизатор PostgreSQL

- в других СУБД (например, в Oracle) есть подсказки оптимизатору
- в PostgreSQL их нет, потому что его разработчики ставили себе целью сделать автоматический верно работающий оптимизатор
- он в подавляющем большинстве случаев прав — вы не сделали бы план лучше, чем делает он

--- 

# Тогда зачем читать этот план выполнения запроса?

- чтобы понять, почему запрос работает неэффективно
- чтобы переписать запрос на более эффективный
- чтобы накинуть индекс
- чтобы понять, что стоит кластеризовать таблицу
- чтобы понять, что надо собрать статистику или уточнить её или расширить её
- чтобы понять, что надо изменить настройки PostgreSQL или сервера — например, добавить оперативной памяти

--- 

# <center>чтобы научиться читать `EXPLAIN`, надо понять, как работает PostgreSQL:)</center>

---

# <center>этим-то мы и займёмся бгг!</center>

---

# Как может выглядеть план запроса, выводимый `EXPLAIN`?

```sql
explain analyze
select e.first_name, e.last_name, ec.phone
from employee e
join employee_contact ec using (employee_id);
```

```text
Hash Join  (cost=366886.39..781776.27 rows=9999990 width=35) (actual time=2387.383..7769.182 rows=10000000 loops=1)
  Hash Cond: (ec.employee_id = e.employee_id)
  ->  Seq Scan on employee_contact ec  (cost=0.00..203092.90 rows=9999990 width=23) (actual time=89.440..1960.488 rows=10000000 loops=1)
  ->  Hash  (cost=173528.84..173528.84 rows=9999884 width=28) (actual time=2295.571..2295.574 rows=10000000 loops=1)
        Buckets: 131072  Batches: 128  Memory Usage: 5925kB
        ->  Seq Scan on employee e  (cost=0.00..173528.84 rows=9999884 width=28) (actual time=0.016..999.143 rows=10000000 loops=1)
Planning Time: 10.470 ms
JIT:
  Functions: 10
  Options: Inlining true, Optimization true, Expressions true, Deforming true
  Timing: Generation 0.302 ms, Inlining 36.612 ms, Optimization 25.924 ms, Emission 26.924 ms, Total 89.762 ms
Execution Time: 8131.726 ms
```

---

# Методы доступа к данным

- нам надо достать какие-то данные, хранящиеся в БД. Как это сделать?
    - полное сканирование таблицы — **seq scan**, sequential scan
    - сканирование с использованием индекса:
        - индексное сканирование — **index scan**
        - сканирование по битовой карте — **bitmap heap scan**
        - сканирование только индекса — **index only scan**

---

# <center>стрелять-колотить, всё сложно!</center>

---

# Полное сканирование

- просто берём и читаем последовательно всю таблицу
- если таблица большая, то это долго и уныло

---

# Полное сканирование

Но иногда это единственный выбор:

```sql
explain analyze select * from employee;
```

```text
Seq Scan on employee  (cost=0.00..173528.84 rows=9999884 width=28) (actual time=1.248..887.986 rows=10000000 loops=1)
Planning Time: 2.139 ms
Execution Time: 1143.016 ms
```

Если надо прочесть всю таблицу — мы просто берём и читаем всю таблицу, да:)

---

# Что выдаёт `EXPLAIN`?

```text
Seq Scan on employee  (cost=0.00..173528.84 rows=9999884 width=28) (actual time=1.248..887.986 rows=10000000 loops=1)
Planning Time: 2.139 ms
Execution Time: 1143.016 ms
```

- Seq Scan — последовательное сканирование таблицы `species`
- cost — оценка стоимости этого узла (узлов может быть несколько)
    - 0.00 — стоимость вывода первой строки этим узлом (подготовительная работа до первой строки)
    - 173528.84 — стоимость вывода всех строк этим узлом
- rows — строк в этом узле

---

# Что такое стоимость?

- оценка трудоёмкости выполнения узла (и всего запроса, состоящего из нескольких узлов)
- входит оценка ресурсов процессора и IO-операций, то есть чтения с диска и записи на диск
- больше обработка данных процессором — выше стоимость
- больше данных читается с диска — выше стоимость

---

# Откуда берётся стоимость?

```sql
select
	relpages, -- количество страниц таблицы (её оценка в статистике)
	current_setting('seq_page_cost'), -- стоимость чтения одной страницы
	relpages * current_setting('seq_page_cost')::int as total -- итог
from pg_class where relname='employee';

|relpages|current_setting|total |
|--------|---------------|------|
|73 530  |1              |73 530|
```

Это оценка IO-операций. Надо считать 73 530 страниц с диска. Стоимость считывания одной страницы равна 1

---

# Откуда берётся стоимость?

```sql
select
	reltuples, -- количество строк
	current_setting('cpu_tuple_cost'), -- стоимость обработки одной строки
	reltuples * current_setting('cpu_tuple_cost')::float as total -- итог
from pg_class where relname='employee';

|reltuples|current_setting|total    |
|---------|---------------|---------|
|9 999 884|0.01           |99 998,84|
```

Это оценка стоимости ресурсов процессора

---

# Итого

73530 + 99998,84 = 173528.84

```sql
explain analyze select * from employee;
```

```text
Seq Scan on employee  (cost=0.00..173528.84 rows=9999884 width=28) (actual time=1.248..887.986 rows=10000000 loops=1)
Planning Time: 2.139 ms
Execution Time: 1143.016 ms
```

Никакой магии, просто формула!

---

# Зафиксируем

Стоимость выполнения запроса (cost) — это индикатор, который позволяет сравнивать стоимость разных запросов и разных планов выполнения запроса.

Больше стоимость — дольше выполняется запрос

---


# Индексное сканирование

```sql
explain analyze select * from employee where employee_id=2;
```

```text
Index Scan using employee_pkey on employee  (cost=0.43..8.45 rows=1 width=28) (actual time=2.077..2.080 rows=1 loops=1)
  Index Cond: (employee_id = 2)
Planning Time: 0.182 ms
Execution Time: 2.108 ms
```

По колонке `employee_id` есть индекс (это первичный ключ), и, раз нам нужны не все строки таблицы, а только одна строка, то эффективно достать её, используя индекс

---

# Индексное сканирование

Как оно работает?

- мы читаем индекс, найдя в нём нужное значение нашей колонки
    - индекс — упорядоченная структура, мы быстро находим там нужное значение даже для огромной таблицы
- найденная в индексе запись ссылается на конкретную страницу таблицы, которая хранит нужную нам строку
    - мы считываем страницу таблицы и вуаля!

---

# Когда фильтруем по колонке с индексом — всегда используем индекс?

Нет!

---

# Когда фильтруем по колонке с индексом — всегда используем индекс?

```sql
explain analyze select * from employee where employee_id>2;
```

```text
Seq Scan on employee  (cost=0.00..198528.55 rows=9999882 width=28) (actual time=18.024..904.382 rows=9999998 loops=1)
  Filter: (employee_id > 2)
  Rows Removed by Filter: 2
Planning Time: 0.668 ms
JIT:
  Functions: 2
  Options: Inlining false, Optimization false, Expressions true, Deforming true
  Timing: Generation 1.047 ms, Inlining 0.000 ms, Optimization 0.991 ms, Emission 17.012 ms, Total 19.051 ms
Execution Time: 1129.669 ms
```

Мы видим тут Seq Scan — последовательное чтение всей таблицы. Почему?

---

# Селективность

- **селективность** — доля выбираемых строк. Отношение выбранных строк к общему количеству строк
    - от 0 до 1. Единица — выбираются все строки. 0.00001 — выбирается малая часть строк
- высокая селективность означает, чтоб выбирается малая доля всех строк

---

# Индекс используется только при высокой селективности

- если надо достать много строк таблицы — незачем читать индекс, легче прочесть всю таблицу целиком
- потому что после чтения индекса надо будет всё равно читать страницы самой таблицы

--- 

# <center>наличие индекса — не гарантия его использования!</center>

---

# <center>если ты запомнишь из доклада только это — это уже будет успехом:)</center>

--- 

# Индекс — только для запросов с высокой селективностью

то есть когда выбирается малая часть всех строк

---

# Bitmap heap scan

- тоже используется индекс
- позволяет не читать несколько раз одну и ту же страницу для разных строк, сначала составляется битовая карта / маска, в которой указываются страницы на чтение, и потом эти страницы считываются из таблицы
- позволяет объединят несколько индексов объединением битовых масок (OR, AND)

---

# Сканирование только индекса

- позволяет не считывать таблицу — если все поля для `select` есть в самом индексе

```sql
create index ... include (...); -- включаем доп столбцы — поиск по ним работать не будет, но доставать их можно будет
```

---

# Итого, методы доступа к данным:

- достаём малый % строк — Index Scan
- побольше — Bitmap Index Scan
- ещё больше — уже Seq Scan

![bg right width:95%](images/graph.png)

---

# Способы соединения таблиц

- nested loop, вложенные циклы
- hash join, соединение хешированием
- merge join, соединение слиянием

---

# Вложенные циклы = nested loop

- как в языке программирования — один цикл вложен в другой

---

# Соединение хешированием = hash join

- меньшая таблица хешируется в памяти (если хватает памяти)
- от колонки соединения берётся хеш и по нему быстро находится значение меньшей таблицы (если оно есть)

---

# Соединение слиянием = merge join

- используется, когда обе таблицы в соединении отсортированы по колонкам соединения
     - или когда стоимость сортировки меньше, чем стоимость других способов соединения

---

# Как играться с методами доступа и способами соединения таблиц?

Их можно временно отключать и смотреть, как это влияет на запрос:

```sql
set enable_seqscan = off;
set enable_indexscan = off;
set enable_bitmapscan = off;
set enable_indexonlyscan = off;

set enable_nestloop = off;
set enable_hashjoin = off;
set enable_mergejoin = off;
```

---

# <center>ооооокей... И что со всем этим делать?</center>

--- 

# Теперь ты можешь читать `EXPLAIN`!

```sql
explain analyze
select e.first_name, e.last_name, ec.phone
from employee e
join employee_contact ec using (employee_id);
```

```text
Hash Join  (cost=366886.39..781776.27 rows=9999990 width=35) (actual time=2387.383..7769.182 rows=10000000 loops=1)
  Hash Cond: (ec.employee_id = e.employee_id)
  ->  Seq Scan on employee_contact ec  (cost=0.00..203092.90 rows=9999990 width=23) (actual time=89.440..1960.488 rows=10000000 loops=1)
  ->  Hash  (cost=173528.84..173528.84 rows=9999884 width=28) (actual time=2295.571..2295.574 rows=10000000 loops=1)
        Buckets: 131072  Batches: 128  Memory Usage: 5925kB
        ->  Seq Scan on employee e  (cost=0.00..173528.84 rows=9999884 width=28) (actual time=0.016..999.143 rows=10000000 loops=1)
Planning Time: 10.470 ms
JIT:
  Functions: 10
  Options: Inlining true, Optimization true, Expressions true, Deforming true
  Timing: Generation 0.302 ms, Inlining 36.612 ms, Optimization 25.924 ms, Emission 26.924 ms, Total 89.762 ms
Execution Time: 8131.726 ms
```

---

# Что происходит?

```text
Hash Join  (cost=366886.39..781776.27 rows=9999990 width=35) (actual time=2387.383..7769.182 rows=10000000 loops=1)
  Hash Cond: (ec.employee_id = e.employee_id)
  ->  Seq Scan on employee_contact ec  (cost=0.00..203092.90 rows=9999990 width=23) (actual time=89.440..1960.488 rows=10000000 loops=1)
  ->  Hash  (cost=173528.84..173528.84 rows=9999884 width=28) (actual time=2295.571..2295.574 rows=10000000 loops=1)
        Buckets: 131072  Batches: 128  Memory Usage: 5925kB
        ->  Seq Scan on employee e  (cost=0.00..173528.84 rows=9999884 width=28) (actual time=0.016..999.143 rows=10000000 loops=1)
Planning Time: 10.470 ms
Execution Time: 8131.726 ms
```

- читаем план снизу вверх — из глубины наружу
- сначала Seq Scan таблицы `employee`
- затем результаты Seq Scan передаются в Hash — в памяти строится хеш-таблица
- затем Seq Scan таблицы `employee_contact`
- и затем эти таблицы соединяются методом Hash Join

---

# На что обращать внимание?

- Seq Scan большой таблицы не может быть быстрым — очевидно
- стоит использовать explain (analyze, buffers), чтобы смотреть, сколько буферов считывается на каждом узле
- стоит смотреть на большие отличия в rows и actual rows — это говорит о неверной статистике
- стоит «думать как СУБД» — насколько план оптимален и почему он такой?

--- 

# `EXPLAIN (ANALYZE BUFFERS)`


```sql
explain (analyze, buffers)
select e.first_name, e.last_name, ec.phone
from employee e
join employee_contact ec using (employee_id)
where employee_id=2;
```

```text
Nested Loop  (cost=0.87..16.92 rows=1 width=35) (actual time=0.173..0.175 rows=1 loops=1)
  Buffers: shared hit=3 read=8
  ->  Index Scan using employee_pkey on employee e  (cost=0.43..8.45 rows=1 width=28) (actual time=0.114..0.114 rows=1 loops=1)
        Index Cond: (employee_id = 2)
        Buffers: shared hit=3 read=4
  ->  Index Scan using employee_contact_pkey on employee_contact ec  (cost=0.43..8.45 rows=1 width=23) (actual time=0.055..0.056 rows=1 loops=1)
        Index Cond: (employee_id = 2)
        Buffers: shared read=4
Planning:
  Buffers: shared hit=102 read=28
Planning Time: 1.281 ms
Execution Time: 0.227 ms
```

---

```text
Nested Loop  (cost=0.87..16.92 rows=1 width=35) (actual time=0.173..0.175 rows=1 loops=1)
  Buffers: shared hit=3 read=8
  ->  Index Scan using employee_pkey on employee e  (cost=0.43..8.45 rows=1 width=28) (actual time=0.114..0.114 rows=1 loops=1)
        Index Cond: (employee_id = 2)
        Buffers: shared hit=3 read=4
  ->  Index Scan using employee_contact_pkey on employee_contact ec  (cost=0.43..8.45 rows=1 width=23) (actual time=0.055..0.056 rows=1 loops=1)
        Index Cond: (employee_id = 2)
        Buffers: shared read=4
Planning:
  Buffers: shared hit=102 read=28
Planning Time: 1.281 ms
Execution Time: 0.227 ms
```

Видно, сколько страниц читается на каждом узле:
- shared hit — прочитано из буфера (из оперативной памяти, она очищается перезапуском PostgreSQL-сервера, например)
- read — прочитано с диска

Если читается много страниц с диска — это не может быть быстро

---

# Не навязывайте план выполнения

- пишите декларативно, не императивно
    - не думайте в формате «достанем сначала это, потом это», используя подзапросы
    - подзапросы — способ навязать способ выполнения запроса, это плохо
    - пусть оптимизатор PostgreSQL сам решит, как лучше выполнять запрос

---

# Статистика

- оптимизатор в плане учитывает планируемое количество строк на каждом узле из своей статистики
- её можно (и нужно обновлять)
    - не отключать auto vacuum на сервере!
    - можно принудительно запускать `VACUUM ANALYZE` для обновления статистики
- можно уточнять статистику, например, через параметр `default_statistics_target`

---

# Более умные индексы

- составные индексы по нескольким колонкам
- покрывающие индексы для Index Only Scan
- индексы по функции — например, индекс по `date_trunc(some_date_field)`
    - тогда индекс может использоваться в запросе `where date_trunc(some_date_field)=...`
- частичные индексы
    - строится на части таблицы, например, для строк, которые хранят почти уникальное в таблице значение по нужной колонке

---

# Короткие и длинные запросы

- короткие запросы — когда количество строк, необходимых для получения результата, невелико независимо от того, насколько велики задействованные таблицы. Короткие запросы могут считывать все строки из маленьких таблиц, но лишь небольшой % строк из больших таблиц
- длинные запросы — если селективность запроса низка по крайней мере для одной из больших таблиц; то есть результат, даже если он невелик, определяется почти всеми строками
    - результат count от большой таблицы — невелик, но задействованы все строки большой таблицы

---

# Оптимизация коротких запросов

- определить наиболее ограничительные критерии (по значениям в таблице) и убедиться, что на эти критерии есть индексы
- подумать об испольховании покрывающего индекса для Index Only Scan
- при построении запроса начни писать его с наиболее ограничительной части, добавляя затем к ней соединения
    - вместо использования соединений и фильтрации его результатов

---

# Оптимизация длинных запросов

- скорее всего это OLAP-запрос, аналитический. Убедись, что он не выполняется часто и много на продакшн базе данных
    - OLTP-запросы не должны быть длинными!
- подумай о внедрении инкрементальных обновлений
    - кешируем результаты в отдельной таблице и добавляем в эту таблицу новые значения вместо переработки всей таблицы
- убедись, что наиболее ограничительная операция выполняется в плане первой, добейся этого
- добейся того, чтобы большие таблицы читались однократно в плане запроса
- такие запросы можно гонять на отдельной БД

--- 

# Как найти наиболее медленные запросы?

- подключите расширение `pg_stat_statements`

```sql
create extension pg_stat_statements;
alter system set shared_preload_libraries = 'pg_stat_statements';
```

(почитайте в документации, где лежит статистика запросов)

---

# Настройки

- можно увеличить `work_mem` (например, до 64 MB) и `hash_mem_multiplier` для увеличения объёма RAM, доступной для операций внутри запроса, в том числе для операций с Hash join
- можно уменьшить `random_page_cost` для быстрых SSD (с 4 до 1.1, например)
- `shared_buffers` стоит установить в 30-40% от доступной памяти на сервере
- конечно, используйте пулер коннектов (Pgbouncer, Odyssey)

---

# Ещё

- денормализация через materialized views, которые по cron'у обновляются
    - очень часто некоторая неактуальность данных — не проблема
- кеширование данных в приложении (в Redis, например)
- секционирование (разбитие большой таблицы на несколько меньших)

---

# Где почитать?


- Книга «Оптимизация запросов в PostgreSQL», Домбровская Г., Новиков Б., Бейликова А.
- Курс Postgres Professional — https://postgrespro.ru/education/courses/QPT
- Книга «Изучаем PostgreSQL 10», Андрей Волков, Джуба С.
- Книга «PostgreSQL 16 изнутри», Рогов Егор
