# ИИ-агенты — вот что действительно изменит разработку. Пишем ИИ-агент на Python и GigaChat

> польза моделей не в том, что они пишут код, а в возможности делать ИИ-агенты

Сразу спойлер — мы тут будем говорить не о том, что ИИ-модели могут писать код и что это якобы драматически изменит мир разработки, избавит бизнес от необходимости нанимать программистов и так далее. Вообще не об этом. Здесь за всем этим хайпом король голый стоит. Люди, задающие промпты, это и есть программисты, и ко всем их текущим знаниям технологического стека просто добавится необходимость владения еще одним инструментом.

Но в теме ИИ-моделей есть что-то кудаааа более интересное, что-то, что действительно меняет разработку и даёт новые возможности. Это ИИ-агенты.

Шо это такое. Говоря по простому, ИИ-агент это система на основе большой языковой модели, которая способна сама решать задачу, взаимодействовать с внешним миром, самостоятельно принимая решения.

Есть моделька, которая понимает человеческий язык, она тупенькая, но понимает человеческий язык и обладает некоторыми базовыми знаниями, скажем, о том, что земля круглая, а функции в питоне определяются со словом `def`. Этой модельке мы даём конкретные инструменты для решения задачи. По сути мы даём ей возможность вызывать конкретный наш код. И моделька сама сможет решить, когда и как вызвать этот наш код для достижения поставленной задачи.

Ещё раз. Не мы пишем if/else для ветвления логики, чтобы определить, какую функцию сейчас надо вызвать, а моделька принимает решение в нужный момент вызвать нужную функцию с нужными параметрами. 

Это огромная смена парадигмы и это то, что уже сейчас работает, и я дальше покажу, как этим реально на практике пользоваться.

По сути что такое программы, которые мы до недавнего времени писали? Вот с 1940х годов, когда была написана и выполнена первая программа Аланом Тьюрингом? Последние 80 лет мы пишем программы, построенные на трёх базовых возможностях:

- хранить и изменять данные,
- делать ветвление логики
- и делать повтор логики, например, через циклы.

Всё. Этого достаточно, чтобы написать любую программу. Любой язык программирования, который даёт эти возможности, является тьюринг-полным и позволяет реализовать любую алгоритмическую задачу.

Тут нет сложных типов и структур данных, нет функций, нет ООП, нет вкусного синтаксического сахара — но используя эти три базовых возможности можно написать любую программу, чем мы успешно и занимались последние 80 лет.

Да, были разработаны более высокоуровневые и удобные языки программирования, на которых разрабатывать программы легче, но все они в конечном итоге это просто хранение и изменение данных в памяти, ветвление логики, то есть if/else и циклы в том или ином виде. Всё. На этих трех концепциях просто накрутили удобного синтаксиса сверху, написали переиспользуемого кода и побежали строчить свои программулечки.

Что же может изменить в этой модели появление больших языковых моделей? Ооо, может изменить многое.

Фактически у нас появился болванчик, который *понимает* обычный человеческий язык. Слово «понимает» я использую здесь в контексте большой языковой модели, конечно, как просто механизм продвинутого автодополнения текста, продвинутый T9. Это грубая аналогия, ок, но LLM это инструмент, который подбирает наиболее релевантное следующее слово, затем следующее и так далее. Да, с учётом семантики, да, токены LLM это не обязательно слова, но в целом, грубо, это так. Подбор наиболее релевантного следующего текста на основе предыдущего текста.

Так вот с этими оговорками, назовём, что LLM *понимает* обычный человеческий язык. Это как ребёнок, который не очень-то силён в каком-то сложном виде деятельности, но он тебя поймёт, когда ты ему скажешь «дай мне вилку» или «закрой дверь» или спросишь, как у него дела. А каким-то более сложным штукам ты или можешь его научить или попросить его для выполнения сложных штук просто звать тебя.

Понимаете?

И вот это «звать тебя» это может быть вызовом вашего кода. Вообще любого произвольного кода, который вы напишете. Этот код может делать что угодно. Модель будет знать о существовании этого кода, в комментариях к коду вы поясните, что этот код делает, что принимает на вход и возвращает на выход — и модель это поймёт. И затем модель сама запросит необходимые данные для вызова вашего кода и в нужный момент вызовет его и передаст в него необходимые аргументы.

То есть вы можете написать, например, на python, но на самом деле на любом ЯП, код, который что-то делает по разработанному вами алгоритму — вот ровно так, как мы это писали 80 лет. Вот прям написать python-функцию, которая принимает на вход сложный объект со своей структурой, какой-нибудь вложенный датакласс, и рассказать модельке, что для выполнения такой-то задачи надо вызвать этот ваш код. И моделька сделает это, а всё недостающее просто спросит у вас или получит из других ваших функций.

И что же тогда получается? А получается, что уже не вы ветвите логику с if/else в вашем ЯП. Сама модель внутри себя принимает решение, что ей делать. Спросить у вас недостающие данные, уточнить что-то, сходить за данными в какую-то вашу python-функцию или базу данных, или собранные и обработанные данные передать в другую python-функцию для выполнения задачи.

Я предприниматель и мне часто нужно готовить бухгалтерские документы. Счета, акты, отчёты и прочее. Брать помощника в штат на такие задачи я пока не решил, не уверен, что смогу его загрузить, но эти задачи надо делать. Мне присылают реквизиты компании в разных форматах — кто-то просто текстом в письме, кто-то в PDF документе, кто-то в ворд документе, кто-то в экселе и так далее. Надо это открыть и в мой шаблон счета или акта аккуратно в нужные места нужные реквизиты скопировать, затем экспортировать шаблон в PDF и отправить на почту или в электронный документооборот. Несложная операция, но занимает время и внимание.

Я подумал — а бахну-ка я ИИ-агента под это дело, чтобы он сам доставал нужные реквизиты из документа любого формата и передавал их в мою python-функцию, которая вставит их в шаблон и сгенерит PDF. Мне было интересно и решить задачу, и проверить эту концепцию, насколько она сейчас реализуема. Спойлер — всё получилось, всё работает.

В качестве модели я решил попробовать использовать сберовский GigaChat. OpenAI-модели запросы с российских IP даже на платных аккаунтах обрабатывать не хочет, а я не хочу решать эту проблему с проксями и VPN'ами. Ну и, конечно, мне было интересно, справится ли российская моделька с моей задачей.

Те, кто уже тянется написать, что это реклама — да, конечно, реклама, ребят. Я за этот видос заработаю кучу денег, тут реклама сбера, huawei (ноут), снова huawei (телефон), снова huawei (планшет), браслета whoop, черной футболки не знаю какого бренда, реклама питона, мне Гвидо ван Россум за каждый видос по котлете отчисляет, реклама носков Henderson, которые сейчас на мне, и так далее.

Хотя на самом деле я потратил несколько дней своего личного времени на создание этого материала и заработаю с него ровно ноль рублей и ноль копеек, поэтому обвинения в рекламе мне всегда особенно приятны. Большое искреннее спасибо тем, кто приходит ко мне на обучение, это вот всё благодаря вам. Курс хардкорная веб-разработка, ссылка в описании к видео.

Кстати, сейчас GigaChat это единственная чисто российская обученная моделька. Она раньше называлась ruGPT, а сейчас называется GigaChat, и её обучали на сберовском суперкомпьютере Кристофари, который так назван в честь первого владельца сберкнижки в 19м веке. YandexGPT использует Qwen, тиньковская моделька тоже. Есть какая-то LLM от МТС, вроде как своя, но я особо информации о ней не нашёл. 

Ну так вот, давайте сделаем ИИ-агента, который будет весело и бодро для меня решать задачу создания для меня бухгалтерских документов по моему шаблону с вызовом моего кода.

Будем использовать API Gigachat с их самой продвинутой моделькой GigaChat-2-Max. После регистрации там даётся 50 тыс токенов бесплатно и затем можно докупить миллион токенов за 1950 руб. Мне на разработку и тесты хватило бесплатных токенов, хотя дальше я уже купил пакет для реального использования.

Исходники все на гитхабе, но сейчас я покажу пошагово как я это делал.

```bash
mkdir ai-accounting-documents

uv init .
uv add langchain langchain-gigachat langgraph python-dotenv

nvim main.py
```

Погнали кодить:

```python
from dataclasses import dataclass, asdict
import json
import os
import subprocess
from typing import Sequence
import uuid

from dotenv import find_dotenv, load_dotenv
from langchain_core.language_models import LanguageModelLike
from langchain_core.runnables import RunnableConfig
from langchain_core.tools import BaseTool, tool
from langchain_gigachat.chat_models import GigaChat
from langgraph.prebuilt import create_react_agent
from langgraph.checkpoint.memory import InMemorySaver


load_dotenv(find_dotenv())

model = GigaChat(
    model="GigaChat-2-Max",
    verify_ssl_certs=False,
)
```

В `.env` кладем ключик:

```text
GIGACHAT_CREDENTIALS=...
```

Надо создать функцию, которая принимает на вход данные контрагента и создаёт акт. Акт я буду создавать с `typst`, это современная замена `latex`, расскажу о ней в отдельном видосе, мне очень понравился этот инструмент для набора и вёрстки документов. Можно, конечно, с чисто питоновскими либами типа pypdf или чем угодно ещё, это к делу не относится. Я пользуюсь typst.

Я создал такой шаблон typst и он берёт данные контрагента из JSON файла и рассовывает эти данные по документу.

И вот такой json ему нужен для работы. Вот такой pdf получается на выходе. Задача LLM достать реквизиты из произвольного файла и передать в мою python-функцию, которая создаст json-файл и вызовем `typst` для создания красивого PDF-документа.

Опишем структуру данных:

```python
@dataclass
class Bank:
    """Банковские реквизиты заказчика"""
    name: str  # наименование банка
    BIC: str  # БИК
    current_account: str  # расчётный счёт
    corporate_account: str  # корреспондентский счёт


@dataclass
class Customer:
    """Заказчик"""
    name: str  # полное название юридического лица, наприемер, ООО «Рога и копыта»
    INN: str  # ИНН
    OGRN: str  # ОГРН или ОГРНИП
    address: str  # юридический адрес
    signatory: str  # подписант
    bank: Bank  # банковские реквизиты заказчика


@dataclass
class Job:
    task: str  # выполненная задача
    price: int  # цена за задачу
```

Накидаем рыбу функции создания акта:

```python
@tool
def generate_pdf_act(customer: Customer, jobs: list[Job]) -> None:
    """
    Генерирует PDF-акт, в котором заполнены данные
    клиента, его банковские реквизиты, а также выполненные задачи

    Args:
        customer (Customer): данные клиента
        jobs (list[Job]): список выполненных задач для внесения в акт

    Returns:
        None
    """
    print(f"generate_pdf_act({asdict(customer)}, {list(map(lambda j: asdict(j), jobs))})")
```

Потом реализуем целиком, а сейчас давайте сделаем так, чтобы моделька вызывала мою функцию:

```python
class LLMAgent:
    def __init__(self, model: LanguageModelLike, tools: Sequence[BaseTool]):
        self._model = model
        self._agent = create_react_agent(
            model,
            tools=tools,
            checkpointer=InMemorySaver())
        self._config: RunnableConfig = {
                "configurable": {"thread_id": uuid.uuid4().hex}}

    def upload_file(self, file):
        file_uploaded_id = self._model.upload_file(file).id_
        return file_uploaded_id

    def invoke(
        self,
        content: str,
        attachments: list[str]|None=None,
        temperature: float=0.1
    ) -> str:
        """Отправляет сообщение в чат"""
        message: dict = {
            "role": "user",
            "content": content,
            **({"attachments": attachments} if attachments else {}) 
        }
        return self._agent.invoke(
            {
                "messages": [message],
                "temperature": temperature
            },
            config=self._config)["messages"][-1].content


def main():
    system_prompt = (
        "Твоя задача сгенерировать акт, для этого тебе надо взять реквизиты "
        "контрагента из приложенного файла, а также запроси работы для включения в "
        "акт (наименования задач и их стоимость), работ может быть несколько. "
        "Никакие данные не придумывай, всё необходимое строго запроси у "
        "пользователя. Имя и отчество подписанта сокращаем до одной первой буквы, "
        "например, Иванов А.Е. "
        "Название компании оборачиваем в кавычки ёлочкой, например, "
        "ООО «Рога и копыта», то есть до названия компании ставим « и после названия "
        "ставим »."
    )
    model = GigaChat(
        model="GigaChat-2-Max",
        verify_ssl_certs=False,
    )

    agent = LLMAgent(model, tools=[generate_pdf_act])
    file_uploaded_id= agent.upload_file(open(REQUISITES_FILE, "rb"))
    #file_uploaded_id = "e866472c-52f7-4582-86cb-d1fcf97e06fa"
    agent_response = agent.invoke(content=system_prompt, attachments=[file_uploaded_id])
    print("LLM: ", agent_response)

    while(True):
        prompt = input("\nТы: ")
        llm_response = agent.invoke(prompt)
        print("LLM: ", llm_response)


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\nдосвидули!")
```

Тут много кода, и сейчас мы на него подробнее посмотрим, но пока что давайте-ка его просто запустим!

Он работает.

Посмотрим как. Температура — 0.1, это степень случайности, 0.1 это менее случайные ответы, 1 это случайные овтеты, то есть там много фантазий и глюков, иногда это полезно, например, при генерации идей, иногда нет, тут фантазии нам не нужны.

Моделька может быть и другой — langchain даёт возможность цеплять сюда любую модель. Хотите установите локально llama или другую модель и используйте её, без проблем.

Ещё важный параметр `config` и в нём `thread_id` — это идентификатор чата, чтобы модель использовала весь контекст чата до этого, а не только последнее сообщение. В качестве хранилища контекста тут используется `checkpointer=InMemorySaver()` , в продакшн надо сохранять контекст в постгресе, например, такая возможность очевидно тоже есть.

---

покажи разные документы с реквизитами, покажи, что берутся верные реквизиты

кто покупал курс — яндекс, сбер, мтс

---

покажи

сделать сайт, 500 000 рублей
сделать сайт, 500 тыс рублей
сделать сайт, 500 тыщ рублей
сделать сайт, двести тыщ
сделать сайт, мильён

---

А теперь давайте сделаем так, чтобы он сам искал реквизиты на почте. Ну а что нет.

---

слой БЛ описывается словами, а в своем коде по сути репозитории

самая сложная важная логика выполняется ллмкой

И плюс интерфейсы не надо писать. LLM выступает интерфейсом к твоей логике!

---

вставь слова цукерберга, главы нвидиа о кол-ве агентов

---

интерфейс это вообще дело десятое — можно обернуть это в телеграм-бота очень легко, например

