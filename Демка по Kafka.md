По результатам чтения [[Книга «Kafka в действии», Дилан Скотт, Виктор Гамов, Дейв Клейн]] (но в большей степени по результатам отдельной проработки).

# Что такое Apache Kafka?

Что такое Apache Kafka? Это продвинутый брокер сообщений. То есть существует много программ, которые являются брокерами сообщений, например, RabbitMQ, Redis Streams, ZeroMQ и другие.

Что такое брокер сообщений? Это программа, которая служит посредником при коммуникации разных систем. Говоря по-простому, одна система записывает сообщения в брокер, а другая система считывает эти сообщения из брокера.

Само слово брокер пошло из финансовой среды, где брокер это посредник между покупателем и продавцом. Например, «Волк с Уолл-стрит» это брокер. В IT это посредник между отправляющей и принимающей системой.

Почему просто не послать запрос от одной системы в другую и нафига нам тут посредник?

Потому что иногда, во-первых, очень удобна именно асинхронная связь, когда одной системе не надо ждать ответа от другой системы.

Во-вторых, когда есть посредник, то отправляющая система и принимающая системы могут вообще не знать друг о друге, что сильно их развязывает. То есть связь этих систем получается слабая, а это очень хорошо. Слабая связь между компонентами большой системы это прекрасно.

Система отправляет событие и ей неважно, кто как его обработает и обработает ли вообще кто-то. Это событие записалось в брокер и какая-то другая система или несколько систем смогут считать из брокера это событие и как-то обработать. При этом кто положил это событие в брокер эти принимающие системы тоже не знают. Просто возникло событие, например, появился новый заказ в ИМ, это событие падает в брокер, и какая-то система, какой-то микросервис, ловит из брокера это событие и обрабатывает, например, отправляет email-сообщение клиенту. Другой микросервис тоже ловит это событие и идёт бронировать товар на склад. И так далее.

В-третьих, брокер может использоваться как потоковая система обработки данных в противовес пакетной обработке данных. Частая схема, когда какие-то выгрузки осуществляются раз в сутки, например. По крону запускается процесс и раз в сутки какие-то данные откуда-то забирает, обрабатывает и куда-то кладёт. Сейчас это не всегда удобно и потоковая система как раз позволяет делать это в реальном времени. Данные при возникновении не собираются в пакет, а кладутся сразу в брокер и сразу могут быть из брокера получены принимающей стороной и обработаны.

Не все брокеры настолько мощны, что их можно назвать потоковой системой обработки данных, но кафка сюда относится.

В-четвертых, брокер может выступать как балансировщик нагрузки. Возникло событие и его может взять обработать любой воркер, то есть любой экземпляр сервиса обработчика. У нас мало заказов — мы подняли одного воркера, который бронирует товары на складе. Стало больше заказов — подняли второго воркера, третьего и так далее. Они просто берут заказы на обработку из брокера и работают. Очень красиво и можно легко горизонтально масштабироваться, просто плодя воркеров в нужном количестве.

В-пятых, принимающая система может сломаться, но сообщение из воркера никуда не пропадёт. Принимающая система поднимется и считает новые необработанные сообщения и обработает их. В случае синхронной связи без посредника, если принимающая сторона лежит, то досвидули — весь процесс падает, мы не можем двигаться дальше. В случае с асинхронной связью и посредником весь процесс не ломается и данные просто обработаются позже.

Отличий Кафки от этих брокеров вроде RabbitMQ, Redis Streams и пр. много.

Кафка отлично горизонтально масштабируется в отличие от других брокеров. Возможность горизонтального дублирования изначально заложено в архитектуру Кафка, это одна из её фундаментальных фич.

Кафка хранит данные постоянно. Скажем, RabbitMQ используется в основном как очередь, то есть один потребитель считал значение из очереди и всё, этого значения в очереди больше нет. В кафке сообщение не удаляется после считывания и его можно считать еще раз другим потребителем или даже спустя какое-то время считать исторические старые данные, чтобы восстановить состояние системы на какой-то период времени в прошлом, например.

Например, микросервис считал данные, но в процессе их обработки возникла ошибка и микросервис упал, не закончив обработку. Вот из кафки не проблема считать данные заново и заново обработать. Или, повторюсь, считать даже через пол года и обработать заново. Очень удобно. Данные могут храниться вечно или удаляться по истечению какого-то срока времени или по нехватке места на диске при необходимости.

Задача потоковой обработки большого объёма данных, это тоже основная задача Kafka, кафка создавалась с прицелом на это. Высочайшая пропускная способность это про кафку, но не всегда про другие брокеры.

# Основные концепции

Окей, про кафку поняли. Поговорим про основные концепции кафки.

## Брокер

Брокер в Kafka это сервер, который принимает сообщения, сохраняет их и передаёт потребителям. Для распределения нагрузки и отказоустойчивости кафка поднимается как правило сразу с несколькими серверами, то есть несколькими брокерами — например, с тремя серверами.

## Продюсер = производитель = producer

Это система, то есть программа, которая пишет сообщения в брокер.

## Потребитель = consumer

Это система, то есть программа, которая читает сообщения из брокера.

## Топик = тема = topic

Топик это логическая категория или канал, куда публикуются сообщения. Например, могут быть топики `logs`, `orders`, `user_activities` и тд. В `logs` пишутся логи системы, в `orders` заказы, в `user_activities` активности пользователей для целей аналитики, например.

Отправители сообщений пишут эти сообщения в соответствующий топик, получатели читают из соответствующего топика. Например, микросервис, отвечающий за создание заказа, после его создания создаёт событие созданного заказа в топике `orders` и все микросервисы, кто должен что-то сделать по факту появления нового заказа, это событие оттуда читают и собственно делают то, что должны.

## Раздел = partition

Каждый топик состоит из одного или нескольких разделов. Разделы нужны для масштабирования нагрузки и отказоустойчивости.

Когда мы отправляем сообщение в кафку, оно запишется в один из разделов. В какой именно раздел? Либо кафка определит сама по принципу round-robin, то есть равномерно между всеми разделами, либо мы можем управлять этим через ключи сообщений, о которых мы поговорим дальше.

Важно, что все данные топика размазываются между разделами. Причем разделы назначаются разным брокерам. То есть, например, в кластере кафки 3 сервера, то есть 3 брокера. Для топика мы создаём 3 раздела. Один раздел ложится на первый сервер, второй раздел на второй сервер, третий раздел на третий сервер. Запись и чтение данных первого раздела будет идти через первый сервер, второго раздела через второй, третьего через третий соответственно.

==покажи тут схему==

![[aac828d097627df1c2d5aacd8f0697aa.png]]

В чем тут кайф? Например, в том, что данные не надо пытаться уместить на одном сервере. Если данных много, их можно размазать по большому количеству серверов. Это и есть партиционирование.

Плюс — когда мы записываем данные, они пишутся в конкретный раздел, не трогая остальные разделы, то есть мы получаем еще и масштабирование нагрузки записи. Аналогично масштабируется и нагрузка чтения, так как читаются данные опять же из конкретного раздела или разделов.

Однако в такой схеме если конкретный брокер ломается, то мы теряем весь раздел. Это уныло. Чтобы такого не было, делают реплики, то есть копии раздела на других серверах, то есть на других брокерах (==покажи==):

![[9b199b118a005c7b8a71bbd086bfb90d.png]]

Лидер каждого раздела хранится на конкретном брокере. Например, лидер раздела 1 на брокере 1, лидер раздела 2 на брокере 2, лидер раздела 3 на брокере 3. Запись и чтение происходят с лидером, а реплики просто догоняют лидера по актуальности. Если брокер ломается, то лидером становится другой брокер. Таким образом достигается отказоустойчивость.

Ну а если нам надо увеличить степень параллелизма записи и чтения — мы можем увеличить количество разделов в топике и число брокеров, то есть серверов.

## Сегменты

Сами разделы хранятся как набор файлов, которые называют сегментами. Не то чтобы это сильно важно — но да.

## Ключ сообщения

При записи сообщения в брокер можно опционально указывать ключ сообщения.

Ключ определяет, в какой конкретный раздел топика попадёт сообщение. Кафка берет хеш от ключа и значение хеша определяет раздел, на который попадёт это сообщение. Соответственно если мы хотим, чтобы какие-то конкретные сообщения попали на один раздел и сохранились там в порядке их добавления, то мы можем указать одинаковый ключ для этих сообщений. Ключом может быть идентификатор пользователя, заказа или еще что-то, что угодно, что мы захотим использовать для попадания конкретных сообщений в один раздел.

Если ключ не задаётся, то сама кафка будет стараться равномерно распределить сообщения по всем доступным разделам по кругу, то есть по алгоритму round-robin.

## Оффсет = сдвиг

Каждое сообщение в разделе имеет свой порядковый номер — сдвиг. Мы можем считывать сообщения по номеру сдвига. При записи новых сообщений они все добавляются в конец раздела и эти сообщения просто нумеруются по порядку.

По сути все эти сообщения хранятся просто в обычных лог-файлах на диске на сервере брокера. Пришло новое сообщение, дописалось в лог, всё. Кафка просто помогает этим всем управлять, но по сути механизм вот такой, ничего сложного. Просто сообщения пишутся в конец файлов и нумеруются, и мы можем считывать сколько хотим раз эти сообщения — последние или старые, как нам нужно.

Потребители используют смещения, чтобы понимать, какое сообщение было последним обработанным, и продолжать обработку с нужной точки после сбоя.

Сообщения, сохранённые в кафке, то есть в этих лог-файлах, неизменяемы. Можно только указать кафке, как долго их хранить, то есть когда их удалять — по истечению времени или по факту занятия какого-то места на диске, например.

Самим сообщением может быть текст или упакованная структура в JSON, Protobuf, Avro и тд.

## Семантика доставки

Продюсеры могут настраивать гарантии доставки сообщений, такие как не более одного раза, не менее одного раза и точно один раз.

- не более одного раза — значит, можно некоторые сообщения потерять. Например, если несколько просмотров страницы из миллиона просмотров потеряются, это некритично
- не менее одного раза — мы не хотим терять сообщения, но можем получить дубликаты сообщения. С ними мы можем сами разобраться в наших потребителях, например, используя какие-то уникальные идентификаторы сообщений и запоминая, что мы уже обработали. То есть если обратка идемпотентна, то это наш выбор
- точно один раз — нам надо доставить строго 1 раз без потерь и дубликатов (есть мнение, что это на практике сложно выдержать в реальной системе, и что особо надеяться на это не стоит, и еще при таком способе доставки будут большие задержки).

## Группа потребителей

Потребителей можно объединять в группы для совместной обработки сообщений одного топика. Каждому потребителю назначается раздел топика и это позволяет обрабатывать данные параллельно. Если потребителей меньше, чем разделов, то какие-то потребители будут обрабатывать несколько разделов, но в целом это то, что позволяет как раз распараллелить чтение данных. Наравне с самими разделами, конечно.

Каждый раздел может быть назначен только одному потребителю в рамках одной группы, что гарантирует, что одно и то же сообщение из конкретного раздела будет обрабатываться только одним потребителем из этой группы.

При этом если нам надо реализовать несколько потоков обработки, то мы можем просто создавать несколько групп потребителей и они будут читать наш топик столько раз, сколько им понадобится.

## Кластер Kafka

Это объединение одного или нескольких серверов, то есть брокеров Kafka. В кластере могут быть тысячи узлов, что позволяет обрабатывать громадные объёмы данных и громадную нагрузку.