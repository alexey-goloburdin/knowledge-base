По результатам чтения [[Книга «Kafka в действии», Дилан Скотт, Виктор Гамов, Дейв Клейн]] (но в большей степени по результатам отдельной проработки).

# Что такое Apache Kafka?

Что такое Apache Kafka? Это продвинутый брокер сообщений. То есть существует много программ, которые являются брокерами сообщений, например, RabbitMQ, Redis Streams, ZeroMQ и другие.

Что такое брокер сообщений? Это программа, которая служит посредником при коммуникации разных систем. Говоря по-простому, одна система записывает сообщения в брокер, а другая система считывает эти сообщения из брокера.

Само слово брокер пошло из финансовой среды, где брокер это посредник между покупателем и продавцом. Например, «Волк с Уолл-стрит» это брокер. В IT это посредник между отправляющей и принимающей системой.

Почему просто не послать запрос от одной системы в другую и нафига нам тут посредник?

Потому что иногда, во-первых, очень удобна именно асинхронная связь, когда одной системе не надо ждать ответа от другой системы.

Во-вторых, когда есть посредник, то отправляющая система и принимающая системы могут вообще не знать друг о друге, что сильно их развязывает. То есть связь этих систем получается слабая, а это очень хорошо. Слабая связь между компонентами большой системы это прекрасно.

Система отправляет событие и ей неважно, кто как его обработает и обработает ли вообще кто-то. Это событие записалось в брокер и какая-то другая система или несколько систем смогут считать из брокера это событие и как-то обработать. При этом кто положил это событие в брокер эти принимающие системы тоже не знают. Просто возникло событие, например, появился новый заказ в ИМ, это событие падает в брокер, и какая-то система, какой-то микросервис, ловит из брокера это событие и обрабатывает, например, отправляет email-сообщение клиенту. Другой микросервис тоже ловит это событие и идёт бронировать товар на склад. И так далее.

В-третьих, брокер может использоваться как потоковая система обработки данных в противовес пакетной обработке данных. Частая схема, когда какие-то выгрузки осуществляются раз в сутки, например. По крону запускается процесс и раз в сутки какие-то данные откуда-то забирает, обрабатывает и куда-то кладёт. Сейчас это не всегда удобно и потоковая система как раз позволяет делать это в реальном времени. Данные при возникновении не собираются в пакет, а кладутся сразу в брокер и сразу могут быть из брокера получены принимающей стороной и обработаны.

Не все брокеры настолько мощны, что их можно назвать потоковой системой обработки данных, но кафка сюда относится.

В-четвертых, брокер может выступать как балансировщик нагрузки. Возникло событие и его может взять обработать любой воркер, то есть любой экземпляр сервиса обработчика. У нас мало заказов — мы подняли одного воркера, который бронирует товары на складе. Стало больше заказов — подняли второго воркера, третьего и так далее. Они просто берут заказы на обработку из брокера и работают. Очень красиво и можно легко горизонтально масштабироваться, просто плодя воркеров в нужном количестве.

В-пятых, принимающая система может сломаться, но сообщение из воркера никуда не пропадёт. Принимающая система поднимется и считает новые необработанные сообщения и обработает их. В случае синхронной связи без посредника, если принимающая сторона лежит, то досвидули — весь процесс падает, мы не можем двигаться дальше. В случае с асинхронной связью и посредником весь процесс не ломается и данные просто обработаются позже.

Отличий Кафки от этих брокеров вроде RabbitMQ, Redis Streams и пр. много.

Кафка отлично горизонтально масштабируется в отличие от других брокеров. Возможность горизонтального дублирования изначально заложено в архитектуру Кафка, это одна из её фундаментальных фич.

Кафка хранит данные постоянно. Скажем, RabbitMQ используется в основном как очередь, то есть один потребитель считал значение из очереди и всё, этого значения в очереди больше нет. В кафке сообщение не удаляется после считывания и его можно считать еще раз другим потребителем или даже спустя какое-то время считать исторические старые данные, чтобы восстановить состояние системы на какой-то период времени в прошлом, например.

Например, микросервис считал данные, но в процессе их обработки возникла ошибка и микросервис упал, не закончив обработку. Вот из кафки не проблема считать данные заново и заново обработать. Или, повторюсь, считать даже через пол года и обработать заново. Очень удобно. Данные могут храниться вечно или удаляться по истечению какого-то срока времени или по нехватке места на диске при необходимости.

Задача потоковой обработки большого объёма данных, это тоже основная задача Kafka, кафка создавалась с прицелом на это. Высочайшая пропускная способность это про кафку, но не всегда про другие брокеры.

# Основные концепции

Окей, про кафку поняли. Поговорим про основные концепции кафки.

## Брокер

Брокер в Kafka это сервер, который принимает сообщения, сохраняет их и передаёт потребителям. Для распределения нагрузки и отказоустойчивости кафка поднимается как правило сразу с несколькими серверами, то есть несколькими брокерами — например, с тремя серверами.
## Топик = тема = topic

Топик это логическая категория или канал, куда публикуются сообщения. Например, могут быть топики `logs`, `orders`, `user_activities` и тд. В `logs` пишутся логи системы, в `orders` заказы, в `user_activities` активности пользователей для целей аналитики, например.

Отправители сообщений пишут эти сообщения в соответствующий топик, получатели читают из соответствующего топика. Например, микросервис, отвечающий за создание заказа, после его создания создаёт событие созданного заказа в топике `orders` и все микросервисы, кто должен что-то сделать по факту появления нового заказа, это событие оттуда читают и собственно делают то, что должны.
## Раздел = partition

Каждый топик состоит из одного или нескольких разделов. Разделы нужны для масштабирования нагрузки и отказоустойчивости.

Когда мы отправляем сообщение в кафку, оно запишется в один из разделов. В какой именно раздел? Либо кафка определит сама по принципу round-robin, то есть равномерно между всеми разделами, либо мы можем управлять этим через ключи сообщений, о которых мы поговорим дальше.

Важно, что все данные топика размазываются между разделами. Причем разделы назначаются разным брокерам. То есть, например, в кластере кафки 3 сервера, то есть 3 брокера. Для топика мы создаём 3 раздела. Один раздел ложится на первый сервер, второй раздел на второй сервер, третий раздел на третий сервер. Запись и чтение данных первого раздела будет идти через первый сервер, второго раздела через второй, третьего через третий соответственно.

==покажи тут схему==

![[aac828d097627df1c2d5aacd8f0697aa.png]]

В чем тут кайф? Например, в том, что данные не надо пытаться уместить на одном сервере. Если данных много, их можно размазать по большому количеству серверов. Это и есть партиционирование.

Плюс — когда мы записываем данные, они пишутся в конкретный раздел, не трогая остальные разделы, то есть мы получаем еще и масштабирование нагрузки записи. Аналогично масштабируется и нагрузка чтения, так как читаются данные опять же из конкретного раздела или разделов.

Однако в такой схеме если конкретный брокер ломается, то мы теряем весь раздел. Это уныло. Чтобы такого не было, делают реплики, то есть копии раздела на других серверах, то есть на других брокерах (==покажи==):

![[9b199b118a005c7b8a71bbd086bfb90d.png]]

Лидер каждого раздела хранится на конкретном брокере. Например, лидер раздела 1 на брокере 1, лидер раздела 2 на брокере 2, лидер раздела 3 на брокере 3. Запись и чтение происходят с лидером, а реплики просто догоняют лидера по актуальности. Если брокер ломается, то лидером становится другой брокер. Таким образом достигается отказоустойчивость.

## Ключ сообщения

При записи сообщения в брокер можно опционально указывать ключ сообщения.

Ключ определяет, в какой конкретный раздел топика попадёт сообщение. Кафка берет хеш от ключа и значение хеша определяет раздел, на который попадёт это сообщение. Соответственно если мы хотим, чтобы какие-то конкретные сообщения попали на один раздел и сохранились там в порядке их добавления, то мы можем указать одинаковый ключ для этих сообщений. Ключом может быть идентификатор пользователя, заказа или еще что-то, что угодно, что мы захотим использовать для попадания конкретных сообщений в один раздел.

Если ключ не задаётся, то сама кафка будет стараться равномерно распределить сообщения по всем доступным разделам по кругу, то есть по алгоритму round-robin.

## Оффсет = сдвиг

Каждое сообщение в разделе имеет свой порядковый номер — сдвиг. Мы можем считывать сообщения по номеру сдвига. При записи новых сообщений они все добавляются в конец раздела и эти сообщения просто нумеруются по порядку.

По сути все эти сообщения хранятся просто в обычных лог-файлах на диске на сервере брокера. Пришло новое сообщение, дописалось в лог, всё. Кафка просто помогает этим всем управлять, но по сути механизм вот такой, ничего сложного. Просто сообщения пишутся в конец файлов и нумеруются, и мы можем считывать сколько хотим раз эти сообщения — последние или старые, как нам нужно.



---
- Один из брокеров назначается лидером для каждого раздела. Лидер обрабатывает все запросы на запись и чтение, а остальные брокеры (реплики) хранят копии раздела для обеспечения отказоустойчивости.
- Если брокер-лидер выходит из строя, другой брокер, который имеет реплику раздела, становится новым лидером. Это помогает поддерживать доступность и целостность данных даже при сбоях.
- Kafka позволяет задавать уровень репликации для каждого топика, указывая, сколько копий каждого раздела необходимо создать. Брокеры отвечают за создание и синхронизацию этих реплик.