- Как PostgreSQL хранит данные. Как смотреть EXPLAIN analyze buffers, сколько считано страниц. В OLTP считывать можно всего неск страниц (см коммент к видосу или посту про связь 1-1), остальное OLTP.
- Связь 1-1
- Нормализация данных и материализованные вьюшки
- Сразу писать эффективные запросы вместо написания как идёт и надежды оптимизировать впоследствии
- Писать декларативные запросы вместо императивных (императивные часто с подзапросами, декларативные просто с join)
- Алгоритмы доступа к данным
- Алгоритмы соединения таблиц
- Короткие и длинные запросы и как их оптимизировать
- Индексы
	- Селективность индекса влияет на то, будет ли использован индекс
	- Index only метод доступа
	- Порядок колонок в индексе и запросе имеет значение (сделай пример)
	- Виды индексов
	- Функциональные индексы
	- Частичные индексы
- Как читать Explain Analyze
- Где смотреть медленные запросы
- Какие параметры влияют на производительность постгреса

Данные хранятся в файлах. Файлы организованы в страницы размером как правило 8КБ. Страница это минимальная единица, которую можно считать с диска и которую можно записать на диск в постгресе. То есть постгрес не умеет считать одну строку из таблицы. Он умеет считать только одну страницу, в которой находится одна конкретная строка. Но помимо этой строки на странице могут быть и другие строки.

Стоимость запроса — это количество тактов процессора и количество операций ввода-вывода.

Как нам достать результаты SQL-запроса `select * from table where field='value'`? Полным сканированием таблицы. Но это медленно. Есть ли способ лучше?

Данные, которые хранятся в таблице, лежат там как? Упорядоченно или нет? Хранятся неупорядоченно, в куче. Где-то, на какой-то странице есть свободное место — мы туда новую строку и вставляем.

---
https://rutube.ru/video/80851eb98742fac5a7b42325edaf5a69/?playlist=452238
13:17

какие-то узлы (nested loop) могут отдавать наверх данные сразу по мере их появления, какие-то только целиком (sort)

планировщик может рассматривать разные планы — использовать разные методы доступа к данным, разным образом соединять таблицы можно, разный порядок соединения таблиц и тд. Чтобы посчитать стоимость плана, которая строится из стоимости каждого узла, надо понимать, сколько строк будет обработано на каждом узле, а для этого нужна статистика

Селективность — доля выбираемых строк, от 0 до 1, 1 если выбираются все строки
Кардинальность — итоговое количество строк, которое выбирается

Стоимость плана — количество тактов процессора и количество IO-операций, то есть операций считывания и записи страниц

Единица стоимости — [стоимость чтения одной странички](https://rutube.ru/video/7b35a0eaf75abb38f5962d99ed064a84/?playlist=452238) (10:35). Стоимость складывается из стоимости операций ввода-вывода и стоимости ресурсов процессора.

Создадим табличку для тестов:

```sql
create table wide_employee (
    employee_id bigint generated always as identity primary key,
    first_name text,
    last_name text,
    phone text,
    email text,
    address text,
    office_id bigint,
    department_id text,
    employment_date date,
    grade smallint,
    referral_id bigint,
    salary bigint,
    photo_url text,
    notes text,
    corporate_money int
);

INSERT INTO wide_employee (
    first_name, last_name, phone, email, address, office_id, department_id,
    employment_date, grade, referral_id, salary, photo_url, notes, corporate_money
)
SELECT 
    -- Случайное имя
    substr(md5(random()::text), 1, 8),
    -- Случайная фамилия
    substr(md5(random()::text), 1, 10),
    -- Случайный номер телефона
    format('(%s) %s-%s', (random() * 900 + 100)::int, (random() * 900 + 100)::int, (random() * 9000 + 1000)::int),
    -- Случайный email
    substr(md5(random()::text), 1, 6) || '@example.com',
    -- Случайный адрес
    format('%s %s St', (random() * 999)::int, substr(md5(random()::text), 1, 6)),
    -- Случайный идентификатор офиса
    (random() * 10 + 1)::int,
    -- Случайный отдел
    CASE WHEN (random() < 0.33) THEN 'HR'
         WHEN (random() < 0.66) THEN 'IT'
         ELSE 'Finance' END,
    -- Случайная дата найма
    '2015-01-01'::date + (random() * 2000)::int,
    -- Случайная оценка (grade)
    (random() * 10 + 1)::int,
    -- Случайный идентификатор рекомендателя
    (random() * 500 + 100)::int,
    -- Случайная зарплата
    (random() * 100000 + 40000)::int,
    -- Случайный URL фотографии
    'http://example.com/photo' || (random() * 10000)::int || '.jpg',
    -- Случайные заметки
    CASE WHEN random() < 0.5 THEN repeat('Hardworking', 50) ELSE repeat('Punctual', 50) END,
    -- Случайное значение корпоративного счёта
    (random() * 5000)::int
FROM generate_series(1, 1000000) AS gs; -- миллион записей

VACUUM FULL ANALYZE wide_employee;
```

Стоимость полного сканирования таблицы, то есть прочесть все её данные:

```sql
explain (analyze, buffers) select * from wide_employee;

Seq Scan on wide_employee  (cost=0.00..95363.00 rows=1000000 width=624) (actual time=0.010..144.900 rows=1000000 loops=1)
Planning Time: 0.251 ms
Execution Time: 171.970 ms
```

>[!info] Цифры в explain
> cost 0..95363. Стоимость начала выполнения работы — то есть стоимость подготовительных работ (тут они не нужны), и второе число это стоимость выполнения всей работы
> 
> rows — количество строк
> 
> width в eplain — размер 1 строки в байтах (нам эта цифра не интересна — смотрим на количество строк и стоимость)


Стоимость ввода-вывода:

```sql
select
	relpages, -- количество страниц таблицы (её оценка в статистике)
	current_setting('seq_page_cost'), -- стоимость чтения одной страницы
	relpages * current_setting('seq_page_cost')::int as total -- итог
from pg_class where relname='wide_employee';

|relpages|current_setting|total |
|--------|---------------|------|
|85 363  |1              |85 363|
```

Стоимость ресурсов процессора:

```sql
select
	reltuples, -- количество строк
	current_setting('cpu_tuple_cost'), -- стоимость обработки одной строки
	reltuples * current_setting('cpu_tuple_cost')::float as total -- итог
from pg_class where relname='wide_employee';

|reltuples|current_setting|total |
|---------|---------------|------|
|1 000 000|0.01           |10 000|
```

Складываем эти 2 числа, получаем стоимость этого узла — последовательного сканирования всей таблицы `wide_employee`. 95 363 — ровно ту стоимость, которую мы видим в `EXPLAIN ANALYZE`. Скажите, круто? Никакой магии. Вот так появляется эта стоимость.

Пример с агрегацией для небольшой таблицы (для большой план будет сложнее):

```sql
explain analyze
select count(*) from observations;

Aggregate  (cost=1.43..1.44 rows=1 width=8) (actual time=0.038..0.038 rows=1 loops=1)
  ->  Seq Scan on observations  (cost=0.00..1.34 rows=34 width=0) (actual time=0.028..0.031 rows=34 loops=1)
Planning Time: 0.186 ms
Execution Time: 0.064 ms
```

Тут есть узел Seq Scan и его данные передаются в верхний узел Aggregate. Причем минимальная стоимость узла Aggregate зависит от полной стоимости нижележащего узла, нечего агрегировать, пока все данные не получены.

Если посмотрим на `count` от большой таблицы — там будет другой план:

```sql
explain analyze
select count(*) from wide_employee;

Finalize Aggregate  (cost=22188.97..22188.98 rows=1 width=8) (actual time=95.821..95.860 rows=1 loops=1)
  ->  Gather  (cost=22188.76..22188.97 rows=2 width=8) (actual time=95.815..95.856 rows=3 loops=1)
        Workers Planned: 2
        Workers Launched: 2
        ->  Partial Aggregate  (cost=21188.76..21188.77 rows=1 width=8) (actual time=85.843..85.843 rows=1 loops=3)
              ->  Parallel Index Only Scan using wide_employee_pkey on wide_employee  (cost=0.42..20147.09 rows=416667 width=0) (actual time=0.116..57.502 rows=333333 loops=3)
                    Heap Fetches: 0
Planning Time: 0.349 ms
Execution Time: 96.032 ms
```

Тут идет параллельное сканирование — причем только индекса по первичному ключу. Миллион разделился на три части и по параллельно идет сканирование двумя воркерами, как видно в плане. Gather собирает данные из воркеров и отдаёт их в вышестоящий узел на дальнейшую уже последовательную обработку. 2 воркера, на выходе 2 строки с количеством строк по каждому воркеру, и на верхнем узле эти 2 числа просто суммируются.

https://rutube.ru/video/8a1713d303fe121828760b55a73de235/?playlist=452238

Индекс — избыточная структура, она дублирует часть информации из таблицы. Если мы удалим индекс, какие-то запросы могут выполняться медленнее, но сами данные мы не потеряем, данные в таблицах не удалятся.

btree — поиск по значению или по диапазону значений (данные в btree в отсортированном виде)

Index only scan — все нужные данные уже в индексе. Покрывающий индекс — всё есть в нём. Там еще читается карта видимости 

```sql
create index ... include (...); -- включаем доп столбцы — поиск по ним работать не будет, но доставать их можно будет
```

Индексы  используются при высокой селективности

---

https://rutube.ru/video/b24dfcfb681ad6b8e5b78d0ab217dd5b/?playlist=452238

сканирование по битовой карте Bitmap Heap Scan и Bitmap Index Scan.

Bitmap heap scan — позволяет не читать несколько раз одну и ту же страницу, сначала составляется битовая карта, и потом читаем в соответствии с ней. Сначала Bitmap Index Scan — строится битовая карта. Затем во внешнем узле Bitmap Heap Scan — читаем по битовой карте саму таблицу.

Сканирование по битовой карте позволяет объединят несколько индексов (OR, AND)

![[Снимок экрана 2024-11-17 в 22.36.01.png]]

Можно отсортировать данные в самой таблице, чтобы данные хранилась упорядоченно (`cluster`)

```sql
cluster table using some_index_name;
```

Можно без блокировки таблицы (какие-то плагины использовать, где-то читал о них).

Кластеризация со временем будет ухудшаться при изменении данных таблицы, добавлении новых данных и тд

---

https://rutube.ru/video/f01dbc4a1849c0a1ee8a1a167c2124b7/?playlist=452238

Соединение Nested loop, вложенный цикл

---

https://rutube.ru/video/bff5152828a6f34a531cf54a67a3c035/?playlist=452238

Соединение хешированием

>[!warning] покажи как отключать в процессе игры разные варианты join'ов и методов доступа

---

https://rutube.ru/video/6d7d1d537e404a0d559a559d5f2c3e99/?playlist=452238

Соединение слиянием, merge join
Удобно когда результат нужен осортированным

---

https://rutube.ru/video/f338430ff0864953a0f18c5f48f0ca49/?playlist=452238

профилирование

расширение `pg_profile` для профилирования постгреса

что оптимизировать? Время — сложно, влияет нагрузка на сервер и тп. Можно оптимизировать IO!

`pg_stat_statements` расширение, стоит устанавливать на все базы данных

```sql
create extension pg_stat_statements;
alter system set shared_preload_libraries = 'pg_stat_statements';

-- restart server
-- sudo pg_ctlcluster 17 main restart

set pg_stat_statements.track = 'all'; -- собирать в тч вложенные подзапросы
```

кандидаты на оптимизация — rows и actual_rows если сильно отличаются, надо оптимизировать (собрать статистику лучше)

и/или настроить глобальные параметры (например, `work_mem` или `hash_mem_multiplier`). `work_mem` — минимальный объём памяти, который выделяется на использование во внутренних операциях, например, на построение hash таблицы, 4 мегабайта дефолтных мало. `hash_mem_multiplier` для операций с hash-таблицами будет выделяться больше памяти, не work_mem, а `work_mem `* `hash_mem_multiplier`.

>[!info] Отключение методов доступа
>enable_seqscan, enable_indexscan, enable_bitmapscan, enable_indexonlyscan

>[!info] Отключение методов соединений
>enable_nestloop, enable_hashjoin, enable_mergejoin

статистика — не отключать auto vacuum
увеличить можно иногда точность статистики `default_statistics_target`

для SSD дисков быстрых можно уменьшить `random_page_cost` c 4 до 1.1, это стоимость чтения рандомной страницы. Стоимость чтения последовательно страницы 1, рандомной больше, но для SSD не так сильно больше, как для накопителя на магнитных дисках.

Нормализация — начинаем с неё, потом при необходимости и с полным пониманием, зачем это делаем, применяем избыточность, то есть денормализацию:
- индексы
- 