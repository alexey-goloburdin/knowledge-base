## Введение

Здоров котаны, вчера вышло видео про оптимизацию вложенных циклов с примером на Python, которое вызвало бурное обсуждение в комментариях и я решил снять дополнение ко этому видосу.

Да, выводы, которые звучали во вчерашнем видосе, оказались поспешными и не всегда правильными, как мы сейчас убедимся.  Сейчас мы наконец-то с вами во всём разберёмся и сделаем прррравильные выводы!

// ну, скорее всего...

## О чём речь

Коротенько напомню, об чём речь. Вывод в видосе: когда у вас есть вложенные циклы, для эффективности имеет смысл цикл меньшего размера ставить наружным, а цикл большего размера ставить внутренним.

В видео демонстрировался совершенно великолепный код на питоняке:

```python
import random
import timeit

ROWS = 5
COLUMNS = 100
TIMEIT_ITERATIONS = 1_000

table = tuple(tuple(random.randint(1000, 10_000)
                    for _ in range(COLUMNS))
              for _ in range(ROWS))

def big_outer_loop():
    overall_sum = 0
    for column in range(COLUMNS):
        for row in range(ROWS):
            overall_sum += table[row][column]

def small_outer_loop():
    overall_sum = 0
    for row in range(ROWS):
        for column in range(COLUMNS):
            overall_sum += table[row][column]


small_outer_loop_time  = timeit.timeit(small_outer_loop, number=TIMEIT_ITERATIONS)
big_outer_loop_time = timeit.timeit(big_outer_loop, number=TIMEIT_ITERATIONS)

delta = round(100*(big_outer_loop_time - small_outer_loop_time) / big_outer_loop_time)
print(f"{delta}%")
```

Здесь есть таблица на 5 строк и 500 колонок и мы проходим эту таблицу либо сначала по колонкам, потом по строкам, либо сначала по строкам, потом по колонкам. И в моём тесте получалось, что эффективнее внешним циклом ставить тот, в котором меньше итераций, потому что это отрабатывало на 20-30% быстрее плюс-минус. Вот сейчас показывает 20%.

## Всё дело в обходе структуры!

В комментариях написали, что это у тебя оно так работает, потому что ты проходишь по структуре и эффективнее проходить по данным, которые лежат на диске или в памяти рядом. Конечно, последовательный доступ к рядом лежащим данным это хорошо, однако, в данном случае это не особо влияет на результаты, давайте в этом убедимся, вообще выбросив таблицу:

```python
import timeit

ROWS = 5
COLUMNS = 100
TIMEIT_ITERATIONS = 1_000

def big_outer_loop():
    overall_sum = 0
    for column in range(COLUMNS):
        for row in range(ROWS):
            overall_sum += 1

def small_outer_loop():
    overall_sum = 0
    for row in range(ROWS):
        for column in range(COLUMNS):
            overall_sum += 1

small_outer_loop_time  = timeit.timeit(small_outer_loop, number=TIMEIT_ITERATIONS)
big_outer_loop_time = timeit.timeit(big_outer_loop, number=TIMEIT_ITERATIONS)

delta = round(100*(big_outer_loop_time - small_outer_loop_time) / big_outer_loop_time)
print(f"{delta}%")
```

То, что вместо обхода таблицы выбрана задача инкремента какой-то переменной — это неважно. На практике любая другая задача здесь может быть. Понятно, что просто посчитать сумму можно проще, здесь это просто для примера как некая простая операция.

Разница получилась 29%.

Здесь может быть предположение, что умный компилятор Python схлопывает эти тупенькие циклы и сразу считает значение `overall_sum`, давайте это проверим. Кстати, в Python есть компилятор — он компилирует исходный код в байткод, который затем выполняется виртуальной машиной Python.  И у нас есть возможность посмотреть этот код байт-код в виде программы на языке ассемблера:

```python
import dis
dis.dis(big_outer_loop)
```

Повторюсь, что это не байт-код, связанный с конкретной системой команд конкретной архитектуры процессора, потому что его выполнять будет Python Virtual Machine, виртуальная машина Python.

Сохраним результаты дизассемблирования двух функций в 2 файла, открываем и убеждаемся, что они идентичны и отличаются только количеством итераций.

```text
  7           0 RESUME                   0

  8           2 LOAD_CONST               1 (0)
              4 STORE_FAST               0 (overall_sum)

  9           6 LOAD_GLOBAL              1 (NULL + range)
             16 LOAD_GLOBAL              2 (COLUMNS)
             26 CALL                     1
             34 GET_ITER
        >>   36 FOR_ITER                27 (to 94)
             40 STORE_FAST               1 (column)

 10          42 LOAD_GLOBAL              1 (NULL + range)
             52 LOAD_GLOBAL              4 (ROWS)
             62 CALL                     1
             70 GET_ITER
        >>   72 FOR_ITER                 7 (to 90)
             76 STORE_FAST               2 (row)

 11          78 LOAD_FAST                0 (overall_sum)
             80 LOAD_CONST               2 (1)
             82 BINARY_OP               13 (+=)
             86 STORE_FAST               0 (overall_sum)
             88 JUMP_BACKWARD            9 (to 72)

 10     >>   90 END_FOR
             92 JUMP_BACKWARD           29 (to 36)

  9     >>   94 END_FOR
             96 RETURN_CONST             0 (None)
```

Левая колонка показывает тут номер строки в Python-коде, средняя колонка показывает команду, правая колонка аргументы команды.

- `RESUME` (*ризююм*) — начало функции
- `LOAD_CONST` — загрузка в стек константы 0
- `STORE_FAST` — сохраняет значение с вершины стека в локальную переменную `overall_sum`
- `LOAD_GLOBAL` — загрузка глобалной функции `range`
- следующий `LOAD_GLOBAL` — загрузка значения `COLUMNS`
- `CALL` — вызов функции `range`
- `GET_ITER` и `FOR_ITER` это работа с итератором, которая тут не раскрывается
- `STORE_FAST` — сохраняет значение с вершины стека в локальную переменную `column`
- `LOAD_GLOBAL` — снова загружается `range` и `ROWS`, затем `CALL` вызывается  `range`, затем сохраняем значение с вершины стека в локальную переменную `row`
- и затем видим тело вложенного цикла — тут нет никакой оптимизации, просто инкремент значения переменной `overall_sum` с командой `BINARY_OP`.
-  Затем `JUMP_BACKWARD` для возврата к вложенному циклу и затем `JUMP_BACKWARD` для возврата ко внешнему циклу для следующей итерации.
- И затем `RETURN_CONST` это выход из функции, с возвратом `None` в данном случае.  

То есть делаем вывод, что никакой оптимизации сложения тут нет и внутрянка обоих циклов идентична. И также делаем вывод, что дело здесь не в том, как мы обходим структуру, а в чем-то другом, потому что мы убрали структуру, а результат тот же.

## Надо просто вынести range за функции!

Также звучали призывы вынести за рамки функций `range`. Давайте это сделаем.

```python
import timeit

ROWS = range(5)
COLUMNS = range(100)
TIMEIT_ITERATIONS = 1_000

def big_outer_loop():
    overall_sum = 0
    for column in COLUMNS:
        for row in ROWS:
            overall_sum += 1

def small_outer_loop():
    overall_sum = 0
    for row in ROWS:
        for column in COLUMNS:
            overall_sum += 1

small_outer_loop_time  = timeit.timeit(small_outer_loop, number=TIMEIT_ITERATIONS)
big_outer_loop_time = timeit.timeit(big_outer_loop, number=TIMEIT_ITERATIONS)

delta = round(100*(big_outer_loop_time - small_outer_loop_time) / big_outer_loop_time)
print(f"{delta}%")
```

Разница все равно в районе 20% остаётся. Изменился ли байткод?

Да, из него пропала очевидным образом загрузка `range` и вызов `range`. В остальном всё работает как и работало и, как показывают цифры, всё равно меньший внешний цикл работает лучше, чем больший внешний цикл.

Давайте заменим вызов генератора на просто кортеж:

```python
ROWS = tuple(range(5))
COLUMNS = tuple(range(100))
```

Разница получилась еще больше — 40%.

## Поговорим об итерациях

На этом мы копать не заканчиваем, но давайте теперь сделаем отступление вообще и циклах и итерациях. Много людей в комментариях написано мне, что я неправильно считаю итерации, складывая количество выполнений внешнего и внутреннего цикла, что количество итераций в обоих случаях 500.

Давайте поговорим о том, зачем вообще я считаю количество раз, которое крутится цикл, допустим, пока не будем называть это итерациями. Потому что мы тут измеряем производительность, а цикл несёт в себе накладные расходы, бесплатно как правило ничего не бывает.

```python
import dis
import timeit

def func1():
    overall = 0
    overall += 1
    overall += 1
    overall += 1
    overall += 1
    overall += 1
    overall += 1
    overall += 1
    overall += 1
    overall += 1
    overall += 1
    return overall

VALUES = tuple(range(10))

def func2():
    overall = 0
    for _ in VALUES:
        overall += 1
    return overall

print(func1(), timeit.timeit(func1, number=1000))
print(func2(), timeit.timeit(func2, number=1000))
```

Что, как думаете, какая функция быстрее будет? Есть ли разница вообще? В первой функции строк кода больше, и вообще это плохой код какой-то, наверняка он дольше будет? А насколько, как думаете?

Видим разницу примерно в 2 раза — функция без цикла работает быстрее. Щас возможно у кого-то открылось прозрение, но цикл не бесплатный!

Опять же, чтобы проверить, что в байт коде нет каких-то хитрых оптимизаций, посмотрим на него. Видим, что `func1` это просто повторение кода инкремента переменной. И видим, что `func2` это просто цикл. Никаких оптимизаций здесь компилятор не делает.

Так почему первый код, который тупо повторяет одну и ту же операцию без цикла, вдруг работает быстрее аж в 2 раза, там плюс-минус? Потому что есть цикл. Потому что он не бесплатный. Здесь не показывается реализация самого цикла FOR в байт-коде, но там в любом случае есть какой-то счетчик, который надо инициализировать, инкрементировать, проверять и так далее, а в случае с тупо перечислением операций без цикла этих всех операций делать не надо.

И именно поэтому я считаю количество сколько раз крутятся оба цикла, внешний и внутренний.

Теперь касательно того, что есть итерация.

Вот [пример цикла](https://metanit.com/assembler/arm64/2.9.php) на настоящем ассемблере, не внутри PVM:

```asm
.global _start

_start:
    mov x0, #0          // регистр X0 - условный счетчик
for_start:              // метка, на которую проецируется цикл
    cmp x0, #5         // сравниваем с некоторым пределом
    b.ge for_end         // условие - если счетчик больше или равен пределу, выход из цикла
    // выполняемые действия
    add x0, x0, 1       //  действия цикла - увеличение счетчика
    b for_start       // повторяем цикл
for_end:
// завершение программы
    mov x8, #93         // номер функции Linux для выхода из программы - 93
    svc 0               // вызываем функцию и выходим из программы
```

Что здесь итерация? Это всё между метками `for_start` и `for_end`. Всё это повторно выполняется при работе цикла. Постоянно код курсирует между этими метками. Это ли не есть итерация? И что же находится между этими метками? А находится там работа со счетчиком и сама полезная нагрузка цикла, оно же тело цикла, которое вы в питоне отделяете табуляцией. Но это всё итерация, не только отделенная табуляцией часть.

Если не хочется по какой-то причине называть это итерациями, и хочется почему-то назвать итерацией только часть кода, которая повторно выполняется при работе цикла, я в целом не против, назовите это операциями, вычислениями, я не знаю, фрикциями, ассимиляциями гиперпостранственного фокала социалистических измерений, пофик ваще. Суть не изменится, этот код многократно выполняется при работе цикла. Я вот по рабоче-крестьянски предпочту это назвать итерацией.

Давайте сделаем свою версию **генератора** `range` и посмотрим, сколько раз она вызовется в случае большего и меньше внешнего цикла:

```python
def my_range(limit):
    counter = 0
    while counter < limit:
        yield 1
        counter += 1
    my_range.called += counter

my_range.called = 0

for _ in my_range(100):
    for _ in my_range(5):
        pass

print(my_range.called)  # 600

my_range.called = 0

for _ in my_range(5):
    for _ in my_range(100):
        pass

print(my_range.called)  # 505
```

Почему, если итераций 500, у нас выводится в одном случае 600, в другом, 505? Да потому что общее число итераций не 500. В одном случае **генератор** суммарно вызвался 600 раз, во втором случае он суммарно вызвался 505 раз.

Но если чо — ассимиляциями гиперпостранственного фокала социалистических измерений это тоже нормальное название, я не против.

## Упрощаем код

Ладно, давайте упростим наш код, чтобы с ним было проще играться.

```python
from functools import partial
import sys
import timeit

BIG_LIMIT = int(sys.argv[1])
SMALL_LIMIT = int(sys.argv[2])
TIMEIT_ITERATIONS = int(sys.argv[3])

def run_loop(outer_loop_limit, inner_loop_limit):
    i = 0
    overall_sum = 0
    while i < outer_loop_limit:
        j = 0
        while j < inner_loop_limit:
            overall_sum += 1
            j += 1
        i += 1
    return overall_sum

print(f"{run_loop(BIG_LIMIT, SMALL_LIMIT)=}, {run_loop(SMALL_LIMIT, BIG_LIMIT)=}")

big = timeit.timeit(partial(run_loop, BIG_LIMIT, SMALL_LIMIT), number=TIMEIT_ITERATIONS)
small = timeit.timeit(partial(run_loop, SMALL_LIMIT, BIG_LIMIT), number=TIMEIT_ITERATIONS)
print(f"delta is {round(100*(big-small)/big)}%")
```

Здесь я решил вынести наружу значения ограничения большего и меньшего циклов, чтобы они принимались из аргументов командной строки при запуске скрипта.

Также я отказался от `for` в пользу явной работы со счётчиками. И также вместо двух функций сделал одну, которая просто вызывается с разными параметрами.

Результат кода аналогичный — меньший внешний цикл работает на примерно 20-30% быстрее.

## Адовые тесты!

Ну так вот. Всё мы значит выяснили, где чо как работает, где какие итерации, что эффективнее и почему. Быгыгы:)

Однако давайте протестируем наш код с разными входными данными.

```shell
$ python3.12 main.py 100 5 1000
func1()=500, func2()=500
delta is 31%

$ python3.12 main.py 1000 5 1000
func1()=5000, func2()=5000
delta is 6%

$ python3.12 main.py 1000 50 1000
func1()=50000, func2()=50000
delta is -18%

$ python3.12 main.py 10000 5 1000
func1()=50000, func2()=50000
delta is 5%
```

Вот это поворот! А почему так?

Быть может, дело в оптимизации компилятора в байткод?

```python
import dis
dis.dis(lambda: func(SMALL_LIMIT, BIG_LIMIT))
exit()
```

```shell
$ python3.12 main.py 100 5 1000 > dis_func1
```

```python
dis.dis(lambda: func(BIG_LIMIT, SMALL_LIMIT))
```

```shell
$ python3.12 main.py 100 5 1000 > dis_func2
$ diff dis_func1 dis_func2

<              12 LOAD_GLOBAL              2 (BIG_LIMIT)
<              22 LOAD_GLOBAL              4 (SMALL_LIMIT)
---
>              12 LOAD_GLOBAL              2 (SMALL_LIMIT)
>              22 LOAD_GLOBAL              4 (BIG_LIMIT)
```

Нет, никаких оптимизаций в байт-коде нет. Байт-код ровно соответствует высокоуровневому коду.

Так, а если вместо `while` с явной работой со счетчиками будет `for`?

```python
from functools import partial
import sys
import timeit

BIG_LIMIT = int(sys.argv[1])
SMALL_LIMIT = int(sys.argv[2])
TIMEIT_ITERATIONS = int(sys.argv[3])

def run_loop(outer_loop_limit, inner_loop_limit):
    i = 0
    overall_sum = 0
    outer_tuple = tuple(range(outer_loop_limit))
    inner_tuple = tuple(range(inner_loop_limit))
    for _ in outer_tuple:
        for _ in inner_tuple:
            overall_sum += 1
    return overall_sum

print(f"{run_loop(BIG_LIMIT, SMALL_LIMIT)=}, {run_loop(SMALL_LIMIT, BIG_LIMIT)=}")

big = timeit.timeit(partial(run_loop, BIG_LIMIT, SMALL_LIMIT), number=TIMEIT_ITERATIONS)
small = timeit.timeit(partial(run_loop, SMALL_LIMIT, BIG_LIMIT), number=TIMEIT_ITERATIONS)
print(f"delta is {round(100*(big-small)/big)}%")
```

Запускаем:

```shell
$ python3.12 main2.py 100 5 1000
run_loop(BIG_LIMIT, SMALL_LIMIT)=500, run_loop(SMALL_LIMIT, BIG_LIMIT)=500
delta is 55%

$ python3.12 main2.py 1000 5 1000
run_loop(BIG_LIMIT, SMALL_LIMIT)=5000, run_loop(SMALL_LIMIT, BIG_LIMIT)=5000
delta is 43%

$ python3.12 main2.py 1000 5 1000
run_loop(BIG_LIMIT, SMALL_LIMIT)=5000, run_loop(SMALL_LIMIT, BIG_LIMIT)=5000
delta is 6%

```




Давайте, поставьте на паузу, и подумайте, откуда разница. Быть может, дело в кеше процессора? Может быть, в хитрой внутренней оптимизации виртуальной машины Python, которая запускает этот байт-код? Может быть, дело в личной закладке Гвидо ван Россума, из-за которой всё работает так?

Давайте, поставьте на паузу и подумайте.

// киваю секунду

Итак, внимание ответ! Да какая нахрен разница:)))

Если подход внешнего меньшего цикла работает лучше при размерах 100 и 5, но хуже при размерах 1000 и 50, то отсюда можно сделать один простой вывод, что не надо нахрен об этом в питоне думать при написании вложенных циклов. Всё!

При оптимизации — возможно, но не при написании. Если у вас есть конкретный вложенный цикл и по результатам профилирования вы выяснили, что он работает медленно и вам кровь из носу как надо его оптимизировать — ну вот как один из вариантов можете попробовать поменять их местами и сравнить результаты, стало лучше и это не погрешность — нормас, стало хуже — откатились обратно.

То есть да, вывод моего прошлого видоса оказался неверным.

Погонял аналогичные тесты на JS, кстати, — результаты такие же, как и для питона, иногда выигрывает один сценарий, иногда другой.

Современные компиляторы, виртуальные машины, механизмы оптимизации внутри процессора — сложны. И даже если нам кажется очевидным, что вот такой способ будет работать тоооочно лучше, это надо тестировать. Возможно, это так, а возможно это не так.

Ну и преждевременная оптимизация зло, как писал еще Кнут. Хотя подход с поменять циклы местами я назвать преждевременной оптимизацией не могу, если это не осложняет код, не ухудшает его читабельность, не делает разработку дольше и сложнее, то это просто эффективное использование имеющихся инструментов, а не оптимизация.

Но тем не менее, повторюсь, в случае питона и JS подход с меньшим внешним циклом работает лучше не всегда, как мы убедились, а значит брать его в общем случае к использованию — не стоит. В то же время иногда он действительно может работать лучше. Надо тестить.

[[Сценарий]]