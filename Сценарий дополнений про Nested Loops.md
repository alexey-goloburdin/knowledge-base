Здоров котаны, вчера вышло видео про оптимизацию вложенных циклов с примером на Python, которое вызвало бурное обсуждение в комментариях и я решил снять дополнение ко этому видосу.

Да, выводы, которые звучали во вчерашнем видосе, оказались поспешными и не всегда правильными, как мы сейчас убедимся. Однако вот сейчас мы с вами во всём разберёмся и сделаем прррравильные выводы!

// ну, скорее всего...

Коротенько напомню, об чём речь. Вывод в видосе: когда у вас есть вложенные циклы, для эффективности имеет смысл цикл меньшего размера ставить наружным, а цикл большего размера ставить внутренним.

В видео демонстрировался совершенно великолепный код на питоняке:

```python
import random
import timeit

ROWS = 5
COLUMNS = 100
TIMEIT_ITERATIONS = 100_000

table = tuple(tuple(random.randint(1000, 10_000)
                    for _ in range(COLUMNS))
              for _ in range(ROWS))

def big_outer_loop():
    overall_sum = 0
    for column in range(COLUMNS):
        for row in range(ROWS):
            overall_sum += table[row][column]

def small_outer_loop():
    overall_sum = 0
    for row in range(ROWS):
        for column in range(COLUMNS):
            overall_sum += table[row][column]


small_time = round(timeit.timeit(small_outer_loop, number=TIMEIT_ITERATIONS), 2)
big_outer_loop_time = round(timeit.timeit(big_outer_loop, number=TIMEIT_ITERATIONS), 2)

delta = round(100*(big_outer_loop_time - small_outer_loop_time) / big_outer_loop_time)
print(f"{delta}%")
```

Здесь есть таблица на 5 строк и 500 колонок и мы проходим эту таблицу либо сначала по колонкам, потом по строкам, либо сначала по строкам, потом по колонкам. И в моём тесте получалось, что эффективнее внешним циклом ставить тот, в котором меньше итераций, потому что это отрабатывало на 27% быстрее.

В комментариях написали, что это у тебя оно так работает, потому что ты проходишь по структуре и эффективнее проходить по данным, которые лежат на диске или в памяти последовательно,. Конечно, последовательный доступ к рядом лежащим данным это хорошо, однако, в данном случае это не особо влияет на результаты, давайте в этом убедимся, вообще выбросив таблицу. Сейчас покажу код.

Также звучали призывы вынести за рамки функций `range`, потому что создание `range` во внутреннем цикле тоже может оказывать своё влияние. Давайте избавимся от `range` и вообще избавимся от неявных счетчиков циклов, потому что то, как я считал итерации в прошлом видео, тоже многим не понравилось, давайте всю подкапотную машинерию просто явно покажем. А то людям кажется, что циклы бесплатны, это не так, конечно, инициализация счетчиков, их инкремент и проверка вполне себе занимают время.

```python
import sys
import timeit

BIG = int(sys.argv[1])
SMALL = int(sys.argv[2])
TIMEIT_ITERATIONS = int(sys.argv[3])

def func1():
    i = 0
    overall_sum = 0
    while i < BIG:
        j = 0
        while j < SMALL:
            overall_sum += 1
            j += 1
        i += 1
    return overall_sum

def func2():
    i = 0
    overall_sum = 0
    while i < SMALL:
        j = 0
        while j < BIG:
            overall_sum += 1
            j += 1
        i += 1
    return overall_sum

print(f"{func1()=}, {func2()=}")

big = timeit.timeit(func1, number=TIMEIT_ITERATIONS)
small = timeit.timeit(func2, number=TIMEIT_ITERATIONS)
print(f"delta is {round(100*(big-small)/big)}%")
```

Два совершенно идентичных цикла. Никаких структур данных не создаётся и не обходится, никаких `range` не используется. Дельта получается 18%:

```shell
$ python3.12 main.py 100 5 100000
func1()=500, func2()=500
delta is 18%
```

18% это не статистическая погрешность, это вполне себе результат.

Если кого-то смущает сложный код циклов с `while` — ну так в циклах с `range` аналогичная логика в конечном итоге выполняется, если есть цикл, который надо выполнить ограниченное количество раз, то есть счетчик этого цикла, который на каждой итерации инкрементируется и проверяется, не вышло ли значение за заданный пример.

Дизасемблированный Python этого нам в данном случаем нам не покажет, потому что он не раскроет реализацию цикла и его счетчика:

```python
def func():
	for index in range(100):
		pass

import dis

dis.dis(func)
  1           0 RESUME                   0

  2           2 LOAD_GLOBAL              1 (NULL + range)
             12 LOAD_CONST               1 (100)
             14 CALL                     1
             22 GET_ITER
        >>   24 FOR_ITER                 2 (to 32)
             28 STORE_FAST               0 (index)
             30 JUMP_BACKWARD            4 (to 24)
        >>   32 END_FOR
             34 RETURN_CONST             0 (None)
```


Левая колонка показывает тут номер строки в Python-коде, средняя колонка показывает команду, правая колонка аргументы команды.

`LOAD_GLOBAL` — загрузка глобальной функции `range`.
`LOAD_CONST` — загрузка в стек константы 100.
`CALL` — вызов функции `range`.
`GET_ITER`  и `FOR_ITER` это работа с итератором, которая тут в коде не раскрывается.
`STORE_FAST` — сохраняет значение с вершины стека в локальную переменную `index`, и затем просто сразу `JUMP_BACKWORD`, то есть уходим обратно на `FOR_ITER`. Когда заканчивается цикл уходим на END_FOR.

Этот байт код выполняет PVM, то есть это не код, связанный с конкретной системой команд конкретной архитектуры процессора. В конечном итоге в этом цикле будет счетчик, который будет изменяться и проверяться на каждой итерации цикла.

Именно поэтому я считал итерации цикла именно таким образом, как это было показано в прошлом видосе, потому что каждая итерация каждого цикла сопряжена с действиями по обслуживанию цикла, то есть по работе с условием выхода из цикла, инкрементом счетчика и проверкой счетчика, не вышло ли его значение за установленным циклом пределы.

Вот [пример цикла](https://metanit.com/assembler/arm64/2.9.php) на настоящем ассемблере, не внутри PVM:

```asm
.global _start

_start:
    mov x0, #0          // регистр X0 - условный счетчик
for_start:              // метка, на которую проецируется цикл
    cmp x0, #5         // сравниваем с некоторым пределом
    b.ge for_end         // условие - если счетчик больше или равен пределу, выход из цикла
    // выполняемые действия
    add x0, x0, 1       //  действия цикла - увеличение счетчика
    b for_start       // повторяем цикл
for_end:
// завершение программы
    mov x8, #93         // номер функции Linux для выхода из программы - 93
    svc 0               // вызываем функцию и выходим из программы
```

Что здесь итерация? Это всё между метками `for_start` и `for_end`. Всё это повторно выполняется при работе цикла. Постоянно код курсирует между этими метками. Это ли не есть итерация? И что же находится между этими метками? А находится там работа со счетчиком и сама полезная нагрузка цикла, оно же тело цикла, которое вы в питоне отделяете табуляцией. Но это всё итерация, не только отделенная табуляцией часть.

Если не хочется по какой-то причине называть это итерациями, я в целом не против, назовите операциями, вычислениями, я не знаю, фрикциями, ассимиляциями гиперпостранственного фокала социалистических измерений, пофик ваще. Суть не изменится, этот код многократно выполняется при работе цикла. Я предпочту это назвать итерацией.

Давайте сделаем свою версию **генератора** `range` и посмотрим, сколько раз она вызовется:

```python
def my_range(limit):
    counter = 0
    while counter < limit:
        yield 1
        counter += 1
    my_range.called += counter

my_range.called = 0

for _ in my_range(100):
    for _ in my_range(5):
        pass

print(my_range.called)  # 600

my_range.called = 0

for _ in my_range(5):
    for _ in my_range(100):
        pass

print(my_range.called)  # 505
```

Почему, если итераций 500, у нас выводится в одном случае 600, в другом, 505? Да потому что общее число итераций не 500. В одном случае **генератор** вызвался 600 раз, во втором случае он вызвался 505 раз.

Но если чо — ассимиляциями гиперпостранственного фокала социалистических измерений это тоже нормальное название, я не против.

Ну так вот.

Как вы думаете, в общем случае что эффективнее — вызвать функцию 505 раз или 600 раз? В общем случае эффективнее вызвать её меньшее количество раз, конечно.

Однако!

Однако давайте протестируем наш код с разными входными данными.

```shell
$ python3.12 main.py 100 5 1000
func1()=500, func2()=500
delta is 31%

$ python3.12 main.py 1000 5 1000
func1()=5000, func2()=5000
delta is 6%

$ python3.12 main.py 1000 50 1000
func1()=50000, func2()=50000
delta is -18%
```

Вот это поворот! А почему так?

Давайте, поставьте на паузу, и подумайте. Быть может, дело в кеше процессора? Может быть, в хитрой внутренней оптимизации виртуальной машины Python, которая запускает этот код? Может быть, дело в личной закладке Гвидо ван Россума, из-за которой всё работает так?

Давайте, поставьте на паузу и подумайте.

// киваю секунду

Итак, внимание ответ! Да какая нахрен разница:)))

Если подход внешнего меньшего цикла работает лучше при размерах 100 и 5, но хуже при размерах 1000 и 50, то отсюда можно сделать один простой вывод, что не надо нахрен об этом в питоне думать при написании вложенных циклов. Всё!

При оптимизации — возможно, но не при написании. Если у вас есть конкретный вложенный цикл и по результатам профилирования вы выяснили, что он работает медленно и вам кровь из носу как надо его оптимизировать — ну вот как один из вариантов можете попробовать поменять их местами и сравнить результаты, стало лучше и это не погрешность — нормас, стало хуже — откатились обратно.

То есть да, вывод моего прошлого видоса оказался неверным.

Погонял аналогичные тесты на JS, кстати, — результаты такие же, как и для питона, иногда выигрывает один сценарий, иногда другой.

Современные компиляторы, виртуальные машины, механизмы оптимизации внутри процессора — сложны. И даже если нам кажется очевидным, что вот такой способ будет работать тоооочно лучше, это надо тестировать. Возможно, это так, а возможно это не так.

Ну и преждевременная оптимизация зло, как писал еще Кнут. Хотя подход с поменять циклы местами я назвать преждевременной оптимизацией не могу, если это не осложняет код, не ухудшает его читабельность, не делает разработку дольше и сложнее, то это просто эффективное использование имеющихся инструментов, а не оптимизация.

Но тем не менее, повторюсь, в случае питона и JS подход с меньшим внешним циклом работает лучше не всегда, как мы убедились, а значит брать его в общем случае к использованию — не стоит. В то же время иногда он действительно может работать лучше. Надо тестить.

[[Сценарий]]